{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "\n",
    " - Use the pipeline here https://www.nltk.org/book/ch03.html\n",
    " - Pull text from here http://www.gutenberg.org/wiki/Children%27s_Instructional_Books_(Bookshelf)\n",
    "  - Install https://www.digitalocean.com/community/tutorials/how-to-work-with-web-data-using-requests-and-beautiful-soup-with-python-3\n",
    "  - Collecting https://www.digitalocean.com/community/tutorials/how-to-scrape-web-pages-with-beautiful-soup-and-python-3\n",
    " - Create function that will pull all texts\n",
    " - Create function that will compare all texts and score them appropriately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps From Prof\n",
    "\n",
    "Overall general comment for homework 2\n",
    " The normalized vocabulary scores should be based on the largest vocabulary of the 100+ texts not from the three (3) texts files from homework 1.  \n",
    "\n",
    "Url link: http://www.gutenberg.org/wiki/Children%27s_Instructional_Books_(Bookshelf)\n",
    "\n",
    "The Bookshelf contains the following categories:\n",
    "- Misc.\n",
    "- Graded Readers\n",
    "- Poetry Readers\n",
    "- Readers for English Speakers Learning Other Languages\n",
    "- Non-English Readers\n",
    "- About Readers\n",
    "- Science and Nature\n",
    "- History\n",
    "- Geography\n",
    "- Uncategorized\n",
    "\n",
    "In your final homework product, please deliver the following:\n",
    "1) WORD or PDF file with your results\n",
    "   - You can elect to put all of your code and results in a Jupyter notebook file in the *.ipynb format, or\n",
    "   - Put all of your python code in a *.py file or multiple *.py files.\n",
    "\n",
    "If you decide to put all of your results in a Jupyter notebook, submit the following\n",
    "2) Jupyter notebook in *.ipynb format, or\n",
    "   - additionally, please upload a *.html file or *.pdf file of the Jupyter notebook file containing the python code\n",
    "\n",
    "Note: \n",
    "Please list all of the Text Mining/Text Analytics software tools used to analyze your homework assignment.\n",
    "\n",
    "I want everyone to get the best score on this assignment.  \n",
    "\n",
    "For those who have already submitted homework 2, if you want to resubmit your homework, please let me know.\n",
    "\n",
    "Please reference the NLP Pipeline listed in chapter 3 or in the following link: \n",
    "- https://www.nltk.org/book/ch03.html\n",
    "\n",
    "to help you frame how would do webscraping to obtain the Gutenberg Instructional Books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_texts = []\n",
    "def fetch_all_texts():\n",
    "    # append to all_texts a dictionary with the raw text\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop through all_texts\n",
    "# Get the largest text\n",
    "# Score each item based on largest text\n",
    "#  - Add text scores to each record of all_texts\n",
    "def score_vocabulary_size():\n",
    "    return 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gl-env]",
   "language": "python",
   "name": "conda-env-gl-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
